{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Abnormality_Detection_VGG16.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "NrWCDfOVpnnW",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VguwGSJOp5ID",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import zipfile\n",
        "\n",
        "\n",
        "zip_ref = zipfile.ZipFile(\"/content/drive/My Drive/Colab Notebooks/MURA-v1.1.zip\", 'r')\n",
        "zip_ref.extractall(\"/tmp/SML\")\n",
        "zip_ref.close()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UKZPDhj4p6rz",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import keras\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dense, Dropout, Flatten\n",
        "from keras.layers import Conv2D, MaxPooling2D\n",
        "from keras.utils import to_categorical\n",
        "from keras.preprocessing import image\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.model_selection import train_test_split\n",
        "from keras.utils import to_categorical\n",
        "from tqdm import tqdm\n",
        "import cv2\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "from tqdm import tqdm\n",
        "import os\n",
        "from keras.preprocessing.image import ImageDataGenerator\n",
        "\n",
        "%matplotlib inline\n",
        "np.random.seed(1)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3Uu0Wl_Op83k",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "df = pd.read_csv(\"/tmp/SML/MURA-v1.1/train_image_paths.csv\",\n",
        "                 names=[\"x_col\"])\n",
        "\n",
        "df['Region'] = df[\"x_col\"].map(lambda x: x.split('/')[-4])\n",
        "df[\"Region\"] = df[\"Region\"].map(lambda x: x.split('XR_')[-1])\n",
        "df[\"y_col\"] = df[\"x_col\"].map(lambda x: x.split('/')[-2])\n",
        "df[\"y_col\"] = df[\"y_col\"].map(lambda x: x.split('_')[-1])\n",
        "df"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FxXsvHIiqEM8",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "X = df[\"x_col\"]\n",
        "y = df[\"Region\"]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZzdQR6cUp-3l",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "df_test = pd.read_csv(\"/tmp/SML/MURA-v1.1/valid_image_paths.csv\",\n",
        "                 names=[\"x_col\"])\n",
        "df_test['Region'] = df_test[\"x_col\"].map(lambda x: x.split('/')[-4])\n",
        "df_test[\"Region\"] = df_test[\"Region\"].map(lambda x: x.split('XR_')[-1])\n",
        "df_test[\"y_col\"] = df_test[\"x_col\"].map(lambda x: x.split('/')[-2])\n",
        "df_test[\"y_col\"] = df_test[\"y_col\"].map(lambda x: x.split('_')[-1])\n",
        "df_test"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IpeGDBeGqBZm",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "X_train_path, X_test_path, y_train, y_test = train_test_split(X, y, test_size = 0.20,stratify=y, random_state = 57)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WzERMDLQqUbF",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "df_train=pd.DataFrame()\n",
        "df_valid = pd.DataFrame()\n",
        "df_train[\"x_col\"]=X_train_path\n",
        "df_train[\"y_col\"]=y_train\n",
        "df_valid[\"x_col\"]=X_test_path\n",
        "df_valid[\"y_col\"]=y_test"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "P__IWu5NqziP",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from keras.applications.vgg16 import VGG16, preprocess_input\n",
        "from keras.optimizers import Adam\n",
        "from keras.models import Model\n",
        "# DATASET_PATH  = '/tmp/SML/MURA-v1.1/train/WRIST'\n",
        "IMAGE_SIZE    = (224, 224)\n",
        "NUM_CLASSES   = 1\n",
        "BATCH_SIZE    = 16  # try reducing batch size or freeze more layers if your GPU runs out of memory\n",
        "FREEZE_LAYERS = 2  # freeze the first this many layers for training\n",
        "NUM_EPOCHS    = 15\n",
        "WEIGHTS_FINAL = 'model-vgg16-abnormal.h5'\n",
        "\n",
        "\n",
        "train_datagen = ImageDataGenerator(preprocessing_function=preprocess_input,\n",
        "                                   rotation_range=20,\n",
        "                                   width_shift_range=0.2,\n",
        "                                   height_shift_range=0.2,\n",
        "                                   shear_range=0.2,\n",
        "                                   zoom_range=0.2,\n",
        "                                   channel_shift_range=10,\n",
        "                                   horizontal_flip=True)\n",
        "\n",
        "train_batches = train_datagen.flow_from_dataframe(\n",
        "        dataframe=df_train,\n",
        "        directory='/tmp/SML',\n",
        "        x_col=\"x_col\",\n",
        "        y_col=\"y_col\",\n",
        "        interpolation='bicubic',\n",
        "        target_size=IMAGE_SIZE,\n",
        "        batch_size=BATCH_SIZE,\n",
        "        class_mode='binary',\n",
        "        shuffle=True,\n",
        "        seed =57)\n",
        "\n",
        "\n",
        "# train_batches = train_datagen.flow_from_directory(DATASET_PATH + '/train',\n",
        "#                                                   target_size=IMAGE_SIZE,\n",
        "#                                                   interpolation='bicubic',\n",
        "#                                                   class_mode='binary',\n",
        "#                                                   shuffle=True,\n",
        "#                                                   batch_size=BATCH_SIZE)\n",
        "\n",
        "valid_datagen = ImageDataGenerator(preprocessing_function=preprocess_input)\n",
        "\n",
        "valid_batches = valid_datagen.flow_from_dataframe(\n",
        "        dataframe=df_valid,\n",
        "        directory='/tmp/SML',\n",
        "        x_col=\"x_col\",\n",
        "        y_col=\"y_col\",\n",
        "        target_size=IMAGE_SIZE,\n",
        "        interpolation='bicubic',\n",
        "        batch_size=BATCH_SIZE,\n",
        "        class_mode='binary',\n",
        "        shuffle=False,\n",
        "        seed = 57)\n",
        "\n",
        "# valid_batches = valid_datagen.flow_from_directory(DATASET_PATH + '/valid',\n",
        "#                                                   target_size=IMAGE_SIZE,\n",
        "#                                                   interpolation='bicubic',\n",
        "#                                                   class_mode='binary',\n",
        "#                                                   shuffle=False,\n",
        "#                                                   batch_size=BATCH_SIZE)\n",
        "\n",
        "test_datagen = ImageDataGenerator(preprocessing_function=preprocess_input)\n",
        "test_batches=test_datagen.flow_from_dataframe(\n",
        "dataframe=df_test,\n",
        "directory=\"/tmp/SML\",\n",
        "x_col=\"x_col\",\n",
        "y_col=None,\n",
        "batch_size=1,\n",
        "seed=57,\n",
        "shuffle=False,\n",
        "class_mode=None,\n",
        "target_size=IMAGE_SIZE)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cx7ky6wKqlWT",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import keras\n",
        "from keras.models import Model, load_model\n",
        "from keras.layers import Activation, Dropout, Flatten, Dense\n",
        "from keras.preprocessing.image import ImageDataGenerator\n",
        "from keras.applications.vgg16 import VGG16\n",
        "\n",
        "\n",
        "#Load the VGG model\n",
        "base_model = VGG16(weights='imagenet', include_top=False, input_shape=(image_size, image_size, 3))\n",
        "\n",
        "#print(base_model.summary())\n",
        "\n",
        "    # Freeze the layers \n",
        "for layer in base_model.layers:\n",
        "    layer.trainable = False\n",
        " \n",
        "# # Create the model\n",
        "model = keras.models.Sequential()\n",
        "\n",
        "# # Add the vgg convolutional base model\n",
        "model.add(base_model)\n",
        " \n",
        "# # Add new layers\n",
        "model.add(Flatten())\n",
        "model.add(Dense(1024, activation='relu'))\n",
        "model.add(Dense(1024, activation='relu'))\n",
        "model.add(Dense(1, activation='sigmoid'))\n",
        " \n",
        "# # Show a summary of the model. Check the number of trainable parameters    \n",
        "#print(model.summary())"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iFZRTteQqnmt",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from keras.optimizers import SGD\n",
        "\n",
        "model.compile(loss='binary_crossentropy',\n",
        "          optimizer=SGD(lr=1e-3),\n",
        "          metrics=['accuracy'])\n",
        "\n",
        "# # Start the training process\n",
        "# model.fit(x_train, y_train, validation_split=0.30, batch_size=32, epochs=50, verbose=2)\n",
        "\n",
        "history = model.fit_generator(\n",
        "        train_batches,\n",
        "        steps_per_epoch=train_batches.n/batch_size,\n",
        "        validation_data = valid_batches,\n",
        "        validation_steps = valid_batches.n/batch_size,\n",
        "        epochs=20)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zOvpow6nrheb",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "score =  model.evaluate_generator(valid_generator,steps=valid_generator.n/batch_size)\n",
        "score"
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}
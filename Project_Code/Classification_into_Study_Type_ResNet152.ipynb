{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Classification_into_Study_Type_ResNet152.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "04NdoJ2CgXxz",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Z2sXW_Vmgh1X",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import zipfile\n",
        "\n",
        "\n",
        "zip_ref = zipfile.ZipFile(\"/content/drive/My Drive/Colab Notebooks/MURA-v1.1.zip\", 'r')\n",
        "zip_ref.extractall(\"/tmp/SML\")\n",
        "zip_ref.close()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HiXNqwPigjio",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import keras\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dense, Dropout, Flatten\n",
        "from keras.layers import Conv2D, MaxPooling2D\n",
        "from keras.utils import to_categorical\n",
        "from keras.preprocessing import image\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.model_selection import train_test_split\n",
        "from keras.utils import to_categorical\n",
        "from tqdm import tqdm\n",
        "import cv2\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "from tqdm import tqdm\n",
        "import os\n",
        "from keras.preprocessing.image import ImageDataGenerator\n",
        "\n",
        "%matplotlib inline\n",
        "np.random.seed(1)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4lLosTW_gmgC",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "df = pd.read_csv(\"/tmp/SML/MURA-v1.1/train_image_paths.csv\",\n",
        "                 names=[\"x_col\"])\n",
        "\n",
        "df['Region'] = df[\"x_col\"].map(lambda x: x.split('/')[-4])\n",
        "df[\"Region\"] = df[\"Region\"].map(lambda x: x.split('XR_')[-1])\n",
        "df[\"y_col\"] = df[\"x_col\"].map(lambda x: x.split('/')[-2])\n",
        "df[\"y_col\"] = df[\"y_col\"].map(lambda x: x.split('_')[-1])\n",
        "df\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "--F3qoUsgpdR",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "df_test = pd.read_csv(\"/tmp/SML/MURA-v1.1/valid_image_paths.csv\",\n",
        "                 names=[\"x_col\"])\n",
        "df_test['Region'] = df_test[\"x_col\"].map(lambda x: x.split('/')[-4])\n",
        "df_test[\"Region\"] = df_test[\"Region\"].map(lambda x: x.split('XR_')[-1])\n",
        "df_test[\"y_col\"] = df_test[\"x_col\"].map(lambda x: x.split('/')[-2])\n",
        "df_test[\"y_col\"] = df_test[\"y_col\"].map(lambda x: x.split('_')[-1])\n",
        "df_test"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Fd_AC0DlguZn",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "X = df[\"x_col\"]\n",
        "y = df[\"Region\"]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "J6Yp3LLngwZT",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "X_train_path, X_test_path, y_train, y_test = train_test_split(X, y, test_size = 0.20,stratify=y, random_state = 57)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IAWpIlyFgyrM",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "df_train=pd.DataFrame()\n",
        "df_valid = pd.DataFrame()\n",
        "df_train[\"x_col\"]=X_train_path\n",
        "df_train[\"y_col\"]=y_train\n",
        "df_valid[\"x_col\"]=X_test_path\n",
        "df_valid[\"y_col\"]=y_test"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zLL9pnkng6WZ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from keras.applications.resnet import ResNet152, preprocess_input\n",
        "from keras.optimizers import Adam\n",
        "from keras.models import Model\n",
        "# DATASET_PATH  = '/tmp/SML/MURA-v1.1/train/WRIST'\n",
        "IMAGE_SIZE    = (224, 224)\n",
        "NUM_CLASSES   = 7\n",
        "BATCH_SIZE    = 16  # try reducing batch size or freeze more layers if your GPU runs out of memory\n",
        "FREEZE_LAYERS = 2  # freeze the first this many layers for training\n",
        "NUM_EPOCHS    = 15\n",
        "WEIGHTS_FINAL = 'model-resnet152-final.h5'\n",
        "\n",
        "\n",
        "train_datagen = ImageDataGenerator(preprocessing_function=preprocess_input,\n",
        "                                   rotation_range=20,\n",
        "                                   width_shift_range=0.2,\n",
        "                                   height_shift_range=0.2,\n",
        "                                   shear_range=0.2,\n",
        "                                   zoom_range=0.2,\n",
        "                                   channel_shift_range=10,\n",
        "                                   horizontal_flip=True)\n",
        "\n",
        "train_batches = train_datagen.flow_from_dataframe(\n",
        "        dataframe=df_train,\n",
        "        directory='/tmp/SML',\n",
        "        x_col=\"x_col\",\n",
        "        y_col=\"y_col\",\n",
        "        interpolation='bicubic',\n",
        "        target_size=IMAGE_SIZE,\n",
        "        batch_size=BATCH_SIZE,\n",
        "        class_mode='categorical',\n",
        "        shuffle=True,\n",
        "        seed =57)\n",
        "\n",
        "\n",
        "# train_batches = train_datagen.flow_from_directory(DATASET_PATH + '/train',\n",
        "#                                                   target_size=IMAGE_SIZE,\n",
        "#                                                   interpolation='bicubic',\n",
        "#                                                   class_mode='binary',\n",
        "#                                                   shuffle=True,\n",
        "#                                                   batch_size=BATCH_SIZE)\n",
        "\n",
        "valid_datagen = ImageDataGenerator(preprocessing_function=preprocess_input)\n",
        "\n",
        "valid_batches = valid_datagen.flow_from_dataframe(\n",
        "        dataframe=df_valid,\n",
        "        directory='/tmp/SML',\n",
        "        x_col=\"x_col\",\n",
        "        y_col=\"y_col\",\n",
        "        target_size=IMAGE_SIZE,\n",
        "        interpolation='bicubic',\n",
        "        batch_size=BATCH_SIZE,\n",
        "        class_mode='categorical',\n",
        "        shuffle=False,\n",
        "        seed = 57)\n",
        "\n",
        "# valid_batches = valid_datagen.flow_from_directory(DATASET_PATH + '/valid',\n",
        "#                                                   target_size=IMAGE_SIZE,\n",
        "#                                                   interpolation='bicubic',\n",
        "#                                                   class_mode='binary',\n",
        "#                                                   shuffle=False,\n",
        "#                                                   batch_size=BATCH_SIZE)\n",
        "\n",
        "test_datagen = ImageDataGenerator(preprocessing_function=preprocess_input)\n",
        "test_batches=test_datagen.flow_from_dataframe(\n",
        "dataframe=df_test,\n",
        "directory=\"/tmp/SML\",\n",
        "x_col=\"x_col\",\n",
        "y_col=None,\n",
        "batch_size=1,\n",
        "seed=57,\n",
        "shuffle=False,\n",
        "class_mode=None,\n",
        "target_size=IMAGE_SIZE)\n",
        "\n",
        "# show class indices\n",
        "print('****************')\n",
        "for cls, idx in train_batches.class_indices.items():\n",
        "    print('Class #{} = {}'.format(idx, cls))\n",
        "print('****************')\n",
        "\n",
        "# build our classifier model based on pre-trained ResNet152:\n",
        "# 1. we don't include the top (fully connected) layers of ResNet152\n",
        "# 2. we add a DropOut layer followed by a Dense (fully connected)\n",
        "#    layer which generates softmax class score for each class\n",
        "# 3. we compile the final model using an Adam optimizer, with a\n",
        "#    low learning rate (since we are 'fine-tuning')\n",
        "net = ResNet152(include_top=False, weights='imagenet', input_tensor=None,\n",
        "               input_shape=(IMAGE_SIZE[0],IMAGE_SIZE[1],3))\n",
        "x = net.output\n",
        "x = Flatten()(x)\n",
        "x = Dropout(0.5)(x)\n",
        "output_layer = Dense(7, activation='softmax', name='softmax')(x)\n",
        "net_final = Model(inputs=net.input, outputs=output_layer)\n",
        "for layer in net_final.layers[:FREEZE_LAYERS]:\n",
        "    layer.trainable = False\n",
        "for layer in net_final.layers[FREEZE_LAYERS:]:\n",
        "    layer.trainable = True\n",
        "net_final.compile(optimizer=Adam(lr=1e-5),\n",
        "                  loss='categorical_crossentropy', metrics=['accuracy'])\n",
        "# print(net_final.summary())\n",
        "\n",
        "# train the model\n",
        "history = net_final.fit_generator(train_batches,\n",
        "                        steps_per_epoch = train_batches.samples // BATCH_SIZE,\n",
        "                        validation_data = valid_batches,\n",
        "                        validation_steps = valid_batches.samples // BATCH_SIZE,\n",
        "                        epochs = NUM_EPOCHS)\n",
        "\n",
        "# save trained weights\n",
        "net_final.save(WEIGHTS_FINAL)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dg9IcyZYhTK-",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "test_batches.reset()\n",
        "pred=net_final.predict_generator(test_batches,\n",
        "steps=test_batches.samples//1,\n",
        "verbose=1)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "E-x2TgJzhVYD",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "predicted_class_indices=np.argmax(pred,axis=1)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7L0xbUKehXXM",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "labels = (train_batches.class_indices)\n",
        "labels = dict((v,k) for k,v in labels.items())\n",
        "predictions = [labels[k] for k in predicted_class_indices]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jUcDKcnNhc5Y",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "df_test[\"pred\"]=predictions\n",
        "y_test = df_test[\"Region\"]\n",
        "y_pred = df_test[\"pred\"]\n",
        "labelencoder_y = LabelEncoder()\n",
        "y_test = labelencoder_y.fit_transform(y_test)\n",
        "y_pred = labelencoder_y.fit_transform(y_pred)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Eug_ZlHWhfIS",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from sklearn import metrics\n",
        "print(\"Accuracy on testing set:\",metrics.accuracy_score(y_test, y_pred))\n",
        "print(\"Error on testing set:\",1-metrics.accuracy_score(y_test, y_pred))\n",
        "print(\"\\n\")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PZMG_rFYhhU4",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from mlxtend.evaluate import confusion_matrix\n",
        "cm = confusion_matrix(y_target=y_test, \n",
        "                      y_predicted=y_pred, \n",
        "                      binary=False)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zkQ4C2cNhjMp",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "\n",
        "recall = np.diag(cm) / np.sum(cm, axis = 1)\n",
        "precision = np.diag(cm) / np.sum(cm, axis = 0)\n",
        "print(\"Precision for ELBOW:\", precision[0])\n",
        "print(\"Precision for FINGER:\", precision[1])\n",
        "print(\"Precision for FOREARM:\", precision[2])\n",
        "print(\"Precision for HAND:\", precision[3])\n",
        "print(\"Precision for HUMERUS:\", precision[4])\n",
        "print(\"Precision for SHOULDER:\", precision[5])\n",
        "print(\"Precision for WRIST:\", precision[6],\"\\n\")\n",
        "print(\"Recall for ELBOW:\", recall[0])\n",
        "print(\"Recall for FINGER:\", recall[1])\n",
        "print(\"Recall for FOREARM:\", recall[2])\n",
        "print(\"Recall for HAND:\", recall[3])\n",
        "print(\"Recall for HUMERUS:\", recall[4])\n",
        "print(\"Recall for SHOULDER:\", recall[5])\n",
        "print(\"Recall for WRIST:\", recall[6],\"\\n\")\n",
        "print(\"Overall Recall\",np.mean(recall))\n",
        "print(\"Overall Precision\", np.mean(precision))\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1iWpgz3uhlpV",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import matplotlib.pyplot as plt\n",
        "from mlxtend.evaluate import confusion_matrix\n",
        "from mlxtend.plotting import plot_confusion_matrix\n",
        "fig, ax = plot_confusion_matrix(conf_mat=cm)\n",
        "\n",
        "plt.show()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QIErWWKChqSz",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Plot training & validation accuracy values\n",
        "plt.plot(history.history['acc'])\n",
        "plt.plot(history.history['val_acc'])\n",
        "plt.title('Model accuracy')\n",
        "plt.ylabel('Accuracy')\n",
        "plt.xlabel('Epoch')\n",
        "plt.legend(['Train', 'Test'], loc='upper left')\n",
        "plt.show()\n",
        "\n",
        "# Plot training & validation loss values\n",
        "plt.plot(history.history['loss'])\n",
        "plt.plot(history.history['val_loss'])\n",
        "plt.title('Model loss')\n",
        "plt.ylabel('Loss')\n",
        "plt.xlabel('Epoch')\n",
        "plt.legend(['Train', 'Test'], loc='upper left')\n",
        "plt.show()"
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}